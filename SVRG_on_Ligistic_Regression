#include <iostream>
#include <fstream>
#include <cassert>
#include <string>
#include<vector>
#include <cstdlib>
#include<random>
#include<ctime>
#include<string.h>
const int M=120,D=24;                  //some parameter of dataset
double w[D];                          //current point w
double w_s[D];                        //snatshop point ws
double d[D];                         //stochastic gradient 
double full_d[D];                    //full gradient
using namespace std;
vector<vector<double>> all_data;
vector<double> all_label;
void load(const char*filename,int M,int D)
{
  //load all datas and labels,aviluable for sparse data espacially
  int i,j=0,pos,ind;
  int count=0,MAX_M=M;
  string tem_str,str_ind,str_val;
  ifstream data_in(filename);
  ofstream data_out("german_data.txt");
  vector<double> tem_vector(D,0);
  
  data_in>>tem_str;
  data_out<<atof(tem_str.c_str());
  all_label.push_back(atof(tem_str.c_str()));
  
  while(count<MAX_M)
  {
    //tem_vector.assign(D,0); 
    data_in>>tem_str;       
    pos=tem_str.find(":");
    if(pos==-1)
    {
      count++;
      all_data.push_back(tem_vector);
      tem_vector.assign(D,0);               //initial tem_vector as 0 
      data_out<<endl;
      if(count<MAX_M)
      {
      data_out<<atof(tem_str.c_str());
      all_label.push_back(atof(tem_str.c_str()));
      }
    }
    else
    {
      str_ind=tem_str.substr(0,pos);
      str_val=tem_str.substr(pos+1);
      ind=stoi(str_ind.c_str());
      tem_vector[ind-1]=stof(str_val.c_str());
      data_out<<" "<<str_val;
    }    
  }
  data_in.close();
  data_out.close();
  //cout<<"count:"<<count<<endl; 
}
int random(int M)
{  
    //generate a random int number in [0,M-1]
    return rand()%M;
} 
double random(double max=1.0)
{
    //generate a random double in [0,max]
   return (double)rand()/RAND_MAX*max;
}
double logistic(int k,double tem_w[D])
{
    double res=0;
    int i;
    for(i=0;i<D;i++)
    res+=all_data[k][i]*tem_w[i];
    res=1/(1+exp(-res));
    return res;
}
void divide_data()
{
  //  
}
void modify_label()
{
  int loop_i;
  for(loop_i=0;loop_i<M;++loop_i)
    all_label[loop_i]=all_label[loop_i]>0;
}
double loss_fun(double w[D])      //value of loss function for logistic regression
{
    //
    double res=0,tem=0;
    int i,j,k;
    for(k=0;k<M;k++)
    {
      for(i=0;i<D;i++)
      {
      tem+=w[i]*all_data[k][i];
      tem=1/(1+exp(-tem));
      }
      res+=(all_label[k]*log(tem)+(1-all_label[k])*log(1-tem));
    }
    res/=M;
    return res;
}
void sto_grad(int k,double tem_w[D])              //stochastic gradient
{
  double tem=0,res=0,zt;
  int i;
  for(i=0;i<D;i++)
    {zt=tem_w[i]*all_data[k][i];
    res+=(tem_w[i]*all_data[k][i]);}
  res=exp(res);
  for(i=0;i<D;i++)
  d[i]=all_label[k]*all_data[k][i]-(all_data[k][i]*res)/(1+res);
} 
void full_grad(double tem_w[D])
{
    int i,k;
    //cout<<all_data[0][0]<<"jcds";
    memset(full_d,0,sizeof(double)*D);
    for(k=0;k<M;++k)
    {
      sto_grad(k,tem_w);                    //calculate full gradient
      for(i=0;i<D;++i)
        full_d[i]+=d[i];
    }
    for(i=0;i<D;++i)
    full_d[i]/=M;
}
double acc(double tem_w[D])
{
  double res=0,count=0;
  int i,j;
  for(i=0;i<M;i++)
    {
      res=logistic(i,tem_w);
      if((res>0.5)==all_label[i])
        count+=1;
    }
  res=count/M;
  return res;
}
void SVRG()
{
    double t=0.00003;            //then stepsize of gradient descent
    int N=30000;                          //the number of iterations
    int option=0;
    //-----------------------------------parameter--------------------------------
    int i,j,k,ind;
    double dir[D]={0},sum[D]={0};
    for(i=0;i<D;++i)   
       w_s[i]=w[i];                              //initial snatshop point w_s using wt   
    for(i=0;i<N+1;++i)
    {
        full_grad(w_s);                         //full gradient of snatshop/w_s point
        for(j=0;j<D;++j)
          w[j]=w_s[j];                          //w0=ws 
        memset(sum,0,sizeof(double)*D);
        for(k=0;k<2*M;++k)
      { 
        ind=random(M);  
        memset(dir,0,sizeof(double)*D);
        sto_grad(ind,w);                         //calculate the stochastic gradient of wt
        for(j=0;j<D;++j) dir[j]+=d[j];
        sto_grad(ind,w_s);                       //calculate the stochastic gradient of ws
        for(j=0;j<D;++j) dir[j]+=d[j];
        for(j=0;j<D;++j) dir[j]+=full_d[j];

        for(j=0;j<D;++j)
          //w[j]=w[j]-t*dir[j];                    //update w when using gradient descent
          w[j]=w[j]+t*dir[j];                    //update w when using gradient ascent
        for(j=0;j<D;++j)
          sum[j]+=w[j];
      }

      if(option==0)                            
       for(j=0;j<D;++j)
        w_s[j]=w[j];                            //update ws using last wt
      else
       for(j=0;j<D;++j)
        w_s[j]=sum[j]/(2*M);                   //update ws using the average of 2M iterations

      if(i%100==0)
        //cout<<"loss function after "<<i+1<<" times iteration is "<<loss_fun(w)<<endl;
        cout<<"the rate of accuracy after "<<i+1<<" times iteration is "<<acc(w)<<endl;
    }
}
void prox(double lamda)            //proximal gradient method
{                                    
    int i;
    for(i=0;i<D;++i)
    if(abs(w[i])<lamda)
      w[i]=0;
    else 
    {
    if(w[i]>lamda)
      w[i]=w[i]-lamda;
    else
      w[i]=w[i]+lamda;
    }
}
void prox_SVRG()
{
    double t=0.001;                      //the stepsize of gradient descent
    int N=30000;                          //the number of iterations
    int option=0;                         
    double lamda=0.0001;                  //parameter of normalization 
    //-----------------------------------parameter--------------------------------
    int i,j,k,ind;
    double dir[D]={0},sum[D]={0};
    for(i=0;i<D;++i)   
       w_s[i]=w[i];                              //initial snatshop point w_s using wt   
    for(i=0;i<N+1;++i)
    {
        full_grad(w_s);                         //full gradient of snatshop/w_s point
        for(j=0;j<D;++j)
          w[j]=w_s[j];                          //w0=ws 
        memset(sum,0,sizeof(double)*D);
        for(k=0;k<2*M;++k)
      { 
        ind=random(M);  
        memset(dir,0,sizeof(double)*D);
        sto_grad(ind,w);                         //calculate the stochastic gradient of wt
        for(j=0;j<D;++j) dir[j]+=d[j];
        sto_grad(ind,w_s);                       //calculate the stochastic gradient of ws
        for(j=0;j<D;++j) dir[j]+=d[j];
        for(j=0;j<D;++j) dir[j]+=full_d[j];

        for(j=0;j<D;++j)
          w[j]=w[j]-t*dir[j];                    //update w 
        prox(lamda);
        for(j=0;j<D;++j)
          sum[j]+=w[j];
      }

      if(option==0)                            
       for(j=0;j<D;++j)
        w_s[j]=w[j];                            //update ws using last wt
      else
       for(j=0;j<D;++j)
        w_s[j]=sum[j]/(2*M);                   //update ws using the average of 2M iterations

      if(i%100==0)
        cout<<"loss function after "<<i+1<<" times iteration is "<<loss_fun(w)<<endl;
    }
}
int main()
{
    int ss;
    double aa=0,max=10.0;
    srand(time(NULL));                //the seed of random 
    char *filename="german.numer.txt";
    load (filename,M,D);
    modify_label();
    for (int i=0;i<D;i++)            //innitialize w
       w[i]=random();
    SVRG();
    //prox_SVRG();
    /*
    for(ss=0;ss<D;++ss)
    cout<<w[ss]<<" ";
    for(ss=0;ss<D;++ss)
    aa+=w[ss]*all_data[2][ss];
    cout<<aa<<" ";
    */
    cin>>aa;
    return 0;
    
}
